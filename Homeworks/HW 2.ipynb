{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6133d0ac-58e4-4ab6-b4dc-b36a8b4d8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"Synapse.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1510cec0-2573-4e70-a042-8333c1ad9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, pos_label=True)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=True)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, precision, recall, fpr, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f532b1fb-84e2-4b9b-94e1-aec16a126596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target, then split into train and test sets\n",
    "X = data.drop(columns=['BUG', 'File'])  # Drop 'BUG' (target) and 'File' (non-numeric)\n",
    "y = data['BUG']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23c4999f-7d6a-4275-a283-958a555ca587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All features\n",
    "X_train_all = X_train\n",
    "X_test_all = X_test\n",
    "\n",
    "# Static features only (replace with your actual static features)\n",
    "static_features = ['WMC', 'DIT', 'NOC', 'CBO', 'RFC', 'LCOM']\n",
    "X_train_static = X_train[static_features]\n",
    "X_test_static = X_test[static_features]\n",
    "\n",
    "# Change features only (replace with your actual change features)\n",
    "change_features = ['SUM_LOC+', 'NO_REV', 'SUM_CHRN']\n",
    "X_train_change = X_train[change_features]\n",
    "X_test_change = X_test[change_features]\n",
    "\n",
    "# Selected top 10 features based on ANOVA F-values\n",
    "selector = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c7777e2-b122-4c31-81db-8f5787705ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (All Features) - Accuracy: 0.9379310344827586, Precision: 0.8421052631578947, Recall: 0.9142857142857143, FPR: 0.05454545454545454, MCC: 0.8365924519026495\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'File' column, which contains non-numeric data, from X_train and X_test\n",
    "X_train = X_train.drop(columns=['File'])\n",
    "X_test = X_test.drop(columns=['File'])\n",
    "\n",
    "# Now, try training the Random Forest model again\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, matthews_corrcoef\n",
    "\n",
    "# Train Random Forest on all features\n",
    "rf_all = RandomForestClassifier(random_state=42)\n",
    "rf_all.fit(X_train, y_train)\n",
    "y_pred_rf_all = rf_all.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy_rf_all = accuracy_score(y_test, y_pred_rf_all)\n",
    "precision_rf_all = precision_score(y_test, y_pred_rf_all, pos_label=True)\n",
    "recall_rf_all = recall_score(y_test, y_pred_rf_all, pos_label=True)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf_all).ravel()\n",
    "fpr_rf_all = fp / (fp + tn)\n",
    "mcc_rf_all = matthews_corrcoef(y_test, y_pred_rf_all)\n",
    "\n",
    "print(f\"Random Forest (All Features) - Accuracy: {accuracy_rf_all}, Precision: {precision_rf_all}, Recall: {recall_rf_all}, FPR: {fpr_rf_all}, MCC: {mcc_rf_all}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e93ea605-f637-4676-be2b-fda486010b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale each feature set\n",
    "X_train_all_scaled = scaler.fit_transform(X_train_all)\n",
    "X_test_all_scaled = scaler.transform(X_test_all)\n",
    "\n",
    "X_train_static_scaled = scaler.fit_transform(X_train_static)\n",
    "X_test_static_scaled = scaler.transform(X_test_static)\n",
    "\n",
    "X_train_change_scaled = scaler.fit_transform(X_train_change)\n",
    "X_test_change_scaled = scaler.transform(X_test_change)\n",
    "\n",
    "X_train_selected_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_selected_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# Run Logistic Regression on scaled data\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Logistic Regression on all features (scaled)\n",
    "accuracy_all, precision_all, recall_all, fpr_all, mcc_all = evaluate_model(log_reg, X_train_all_scaled, X_test_all_scaled, y_train, y_test)\n",
    "\n",
    "# Logistic Regression on static features (scaled)\n",
    "accuracy_static, precision_static, recall_static, fpr_static, mcc_static = evaluate_model(log_reg, X_train_static_scaled, X_test_static_scaled, y_train, y_test)\n",
    "\n",
    "# Logistic Regression on change features (scaled)\n",
    "accuracy_change, precision_change, recall_change, fpr_change, mcc_change = evaluate_model(log_reg, X_train_change_scaled, X_test_change_scaled, y_train, y_test)\n",
    "\n",
    "# Logistic Regression on selected features (scaled)\n",
    "accuracy_selected, precision_selected, recall_selected, fpr_selected, mcc_selected = evaluate_model(log_reg, X_train_selected_scaled, X_test_selected_scaled, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3e2fd9bc-f185-4dcd-9c3e-9d999a3e4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest on all features\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "accuracy_rf_all, precision_rf_all, recall_rf_all, fpr_rf_all, mcc_rf_all = evaluate_model(rf, X_train_all, X_test_all, y_train, y_test)\n",
    "\n",
    "# Random Forest on static features\n",
    "accuracy_rf_static, precision_rf_static, recall_rf_static, fpr_rf_static, mcc_rf_static = evaluate_model(rf, X_train_static, X_test_static, y_train, y_test)\n",
    "\n",
    "# Random Forest on change features\n",
    "accuracy_rf_change, precision_rf_change, recall_rf_change, fpr_rf_change, mcc_rf_change = evaluate_model(rf, X_train_change, X_test_change, y_train, y_test)\n",
    "\n",
    "# Random Forest on selected features\n",
    "accuracy_rf_selected, precision_rf_selected, recall_rf_selected, fpr_rf_selected, mcc_rf_selected = evaluate_model(rf, X_train_selected, X_test_selected, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7420d9cb-004a-4ee3-bd68-38f27a3457cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Algorithm  Features Testing%  Accuracy  Precision    Recall  \\\n",
      "0  LogisticRegression       All      20%  0.896552   0.777778  0.800000   \n",
      "1  LogisticRegression    Static      20%  0.793103   0.692308  0.257143   \n",
      "2  LogisticRegression    Change      20%  0.855172   0.818182  0.514286   \n",
      "3  LogisticRegression  Selected      20%  0.862069   0.727273  0.685714   \n",
      "4        RandomForest       All      20%  0.937931   0.842105  0.914286   \n",
      "5        RandomForest    Static      20%  0.744828   0.466667  0.400000   \n",
      "6        RandomForest    Change      20%  0.903448   0.783784  0.828571   \n",
      "7        RandomForest  Selected      20%  0.958621   0.871795  0.971429   \n",
      "\n",
      "        FPR       MCC  \n",
      "0  0.072727  0.720383  \n",
      "1  0.036364  0.330697  \n",
      "2  0.036364  0.570064  \n",
      "3  0.081818  0.616349  \n",
      "4  0.054545  0.836592  \n",
      "5  0.145455  0.268897  \n",
      "6  0.072727  0.741908  \n",
      "7  0.045455  0.893602  \n"
     ]
    }
   ],
   "source": [
    "# Consolidate results\n",
    "results = pd.DataFrame({\n",
    "    'Algorithm': ['LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', \n",
    "                  'RandomForest', 'RandomForest', 'RandomForest', 'RandomForest'],\n",
    "    'Features': ['All', 'Static', 'Change', 'Selected', 'All', 'Static', 'Change', 'Selected'],\n",
    "    'Testing%': ['20%'] * 8,\n",
    "    'Accuracy': [accuracy_all, accuracy_static, accuracy_change, accuracy_selected,\n",
    "                 accuracy_rf_all, accuracy_rf_static, accuracy_rf_change, accuracy_rf_selected],\n",
    "    'Precision': [precision_all, precision_static, precision_change, precision_selected,\n",
    "                  precision_rf_all, precision_rf_static, precision_rf_change, precision_rf_selected],\n",
    "    'Recall': [recall_all, recall_static, recall_change, recall_selected,\n",
    "               recall_rf_all, recall_rf_static, recall_rf_change, recall_rf_selected],\n",
    "    'FPR': [fpr_all, fpr_static, fpr_change, fpr_selected,\n",
    "            fpr_rf_all, fpr_rf_static, fpr_rf_change, fpr_rf_selected],\n",
    "    'MCC': [mcc_all, mcc_static, mcc_change, mcc_selected,\n",
    "            mcc_rf_all, mcc_rf_static, mcc_rf_change, mcc_rf_selected]\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe18f596-40f5-4b0c-81b3-18e02f2993c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              WMC         DIT         NOC         CBO         RFC  \\\n",
      "count  723.000000  723.000000  723.000000  723.000000  723.000000   \n",
      "mean     8.193638    0.699862    0.333333   12.901798   30.414938   \n",
      "std      9.766732    0.613638    2.487271   14.672134   31.253621   \n",
      "min      1.000000    0.000000    0.000000    0.000000    1.000000   \n",
      "25%      3.000000    0.000000    0.000000    6.000000   10.500000   \n",
      "50%      5.000000    1.000000    0.000000   10.000000   23.000000   \n",
      "75%      9.000000    1.000000    0.000000   14.500000   39.000000   \n",
      "max     95.000000    4.000000   38.000000  161.000000  231.000000   \n",
      "\n",
      "              LCOM          CA         CE         NPM       LCOM3  ...  \\\n",
      "count   723.000000  723.000000  723.00000  723.000000  723.000000  ...   \n",
      "mean     43.373444    4.421853    8.75657    6.236515    1.055296  ...   \n",
      "std     201.221103   12.120833    8.66786    8.659659    0.661150  ...   \n",
      "min       0.000000    0.000000    0.00000    0.000000    0.000000  ...   \n",
      "25%       1.000000    1.000000    3.00000    2.000000    0.600000  ...   \n",
      "50%       3.000000    2.000000    7.00000    3.000000    0.833333  ...   \n",
      "75%      15.000000    4.000000   11.00000    7.000000    2.000000  ...   \n",
      "max    2527.000000  155.000000   70.00000   91.000000    2.000000  ...   \n",
      "\n",
      "         MAX_LOC+    SUM_LOC-    MAX_LOC-     MAX_SET     AVG_SET      NO_REV  \\\n",
      "count  723.000000  723.000000  723.000000  723.000000  723.000000  723.000000   \n",
      "mean    12.958506    4.827109    3.706777   10.822960    7.801176    0.789765   \n",
      "std     50.489443   15.905338   12.486771   22.596403   17.670616    1.501635   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      4.000000    2.000000    2.000000    7.000000    5.810000    1.000000   \n",
      "max    811.000000  148.000000  122.000000   96.000000   96.000000   13.000000   \n",
      "\n",
      "         SUM_CHRN    MAX_CHRN         Age  CountOfDeveloper  \n",
      "count  723.000000  723.000000  723.000000        723.000000  \n",
      "mean    20.283541   16.297372   96.707607          0.486860  \n",
      "std     64.057830   54.652656   90.477210          0.739305  \n",
      "min      0.000000    0.000000  -79.000000          0.000000  \n",
      "25%      0.000000    0.000000   26.140000          0.000000  \n",
      "50%      0.000000    0.000000  106.280000          0.000000  \n",
      "75%      8.000000    6.500000  172.070000          1.000000  \n",
      "max    814.000000  811.000000  224.710000          4.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "sns.countplot(x='BUG', data=data)\n",
    "plt.title(\"Distribution of Buggy vs Non-Buggy Files\")\n",
    "plt.show()\n",
    "\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9d00ad4e-a19a-495a-bf4e-3ab9fd327441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['RFC', 'CE', 'LOC', 'SUM_LOC-', 'MAX_LOC-', 'MAX_SET', 'AVG_SET',\n",
      "       'NO_REV', 'Age', 'CountOfDeveloper'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Perform feature selection on the training data\n",
    "selector = SelectKBest(score_func=f_classif, k=10)  # Select top 10 features\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Retrieve the selected features\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "print(\"Selected features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dd9b32eb-061f-4951-8d2f-d3bae6f06890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It signifies that the selected features provide maximum classification accuracy as they cover the sufficient statistics of predictors in buggy code. WMC and RFC are code complexity-related features and strong indicators of bug-prone files. Metrics like SUM_LOC+ and Age reflect recent changes as well as code age, both of which are important bug predictors. Besides avoiding overfitting and reducing noise, minimizing the feature set to the most relevant ones allows for better generalization of the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "057dd192-8142-4ee0-bc21-60e1932d664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, precision, recall, fpr, mcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3dfa2e5a-de25-4ec8-8dfd-e53e260fbdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Evaluate SVM on all features\n",
    "accuracy_svm_all, precision_svm_all, recall_svm_all, fpr_svm_all, mcc_svm_all = evaluate_model(\n",
    "    svm_model, X_train_all, X_test_all, y_train, y_test\n",
    ")\n",
    "\n",
    "# Evaluate SVM on static features\n",
    "accuracy_svm_static, precision_svm_static, recall_svm_static, fpr_svm_static, mcc_svm_static = evaluate_model(\n",
    "    svm_model, X_train_static, X_test_static, y_train, y_test\n",
    ")\n",
    "\n",
    "# Evaluate SVM on change features\n",
    "accuracy_svm_change, precision_svm_change, recall_svm_change, fpr_svm_change, mcc_svm_change = evaluate_model(\n",
    "    svm_model, X_train_change, X_test_change, y_train, y_test\n",
    ")\n",
    "\n",
    "# Evaluate SVM on selected features\n",
    "accuracy_svm_selected, precision_svm_selected, recall_svm_selected, fpr_svm_selected, mcc_svm_selected = evaluate_model(\n",
    "    svm_model, X_train_selected, X_test_selected, y_train, y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2abcd94c-70be-4ff7-91eb-e51ee06e053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Algorithm  Features Testing%  Accuracy  Precision    Recall  \\\n",
      "0   LogisticRegression       All      20%  0.896552   0.777778  0.800000   \n",
      "1   LogisticRegression    Static      20%  0.793103   0.692308  0.257143   \n",
      "2   LogisticRegression    Change      20%  0.855172   0.818182  0.514286   \n",
      "3   LogisticRegression  Selected      20%  0.862069   0.727273  0.685714   \n",
      "4         RandomForest       All      20%  0.937931   0.842105  0.914286   \n",
      "5         RandomForest    Static      20%  0.744828   0.466667  0.400000   \n",
      "6         RandomForest    Change      20%  0.903448   0.783784  0.828571   \n",
      "7         RandomForest  Selected      20%  0.958621   0.871795  0.971429   \n",
      "8                  SVM       All      20%  0.889655   0.756757  0.800000   \n",
      "9                  SVM    Static      20%  0.793103   0.727273  0.228571   \n",
      "10                 SVM    Change      20%  0.917241   0.767442  0.942857   \n",
      "11                 SVM  Selected      20%  0.179310   0.144068  0.485714   \n",
      "\n",
      "         FPR       MCC  \n",
      "0   0.072727  0.720383  \n",
      "1   0.036364  0.330697  \n",
      "2   0.036364  0.570064  \n",
      "3   0.081818  0.616349  \n",
      "4   0.054545  0.836592  \n",
      "5   0.145455  0.268897  \n",
      "6   0.072727  0.741908  \n",
      "7   0.045455  0.893602  \n",
      "8   0.081818  0.704940  \n",
      "9   0.027273  0.325329  \n",
      "10  0.090909  0.798195  \n",
      "11  0.918182 -0.475402  \n"
     ]
    }
   ],
   "source": [
    "# Add SVM results to a DataFrame\n",
    "results_svm = pd.DataFrame({\n",
    "    'Algorithm': ['SVM', 'SVM', 'SVM', 'SVM'],\n",
    "    'Features': ['All', 'Static', 'Change', 'Selected'],\n",
    "    'Testing%': ['20%'] * 4,\n",
    "    'Accuracy': [accuracy_svm_all, accuracy_svm_static, accuracy_svm_change, accuracy_svm_selected],\n",
    "    'Precision': [precision_svm_all, precision_svm_static, precision_svm_change, precision_svm_selected],\n",
    "    'Recall': [recall_svm_all, recall_svm_static, recall_svm_change, recall_svm_selected],\n",
    "    'FPR': [fpr_svm_all, fpr_svm_static, fpr_svm_change, fpr_svm_selected],\n",
    "    'MCC': [mcc_svm_all, mcc_svm_static, mcc_svm_change, mcc_svm_selected]\n",
    "})\n",
    "\n",
    "# Combine the SVM results with existing results\n",
    "results_combined = pd.concat([results, results_svm], ignore_index=True)\n",
    "\n",
    "# Display the combined results\n",
    "print(results_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950656d6-005b-4e0c-bff5-b59d97950469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#These features probably reflect the most relevant metrics for bug prediction, such as WMC, RFC, and SUM_LOC+, and eliminated less predictive or redundant features. This enabled the SVM model to generalize more effectively and achieve better accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebc9c9-bcf8-41b8-85d5-e45dbca0f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5: The Random Forest with Selected Features achieved the best overall performance with an accuracy of 95.86%, precision of 87.18%, recall of 97.14%, and MCC of 0.894.\n",
    "#This combination not only maximizes accuracy but also balances precision, recall, and a low False Positive Rate (FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60bff5-c834-4d06-8cfd-7ef05756b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5a: Complexity: Random Forests are more complex than Logistic Regression and SVM. The use of multiple decision trees can make the model slower to train and harder to interpret.\n",
    "#Overfitting Potential: While Random Forests are less prone to overfitting than individual decision trees, they can still overfit if the data is noisy or improperly preprocessed.\n",
    "#Computational Cost: Training and inference for Random Forests can be more computationally expensive compared to simpler models like Logistic Regression or SVM, especially with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d1560c35-6415-40b5-a5f2-943a0ef60dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5b: Metric Used: Accuracy: Random Forest with Selected Features had the highest accuracy of 95.86%, which reflects the overall correctness of predictions. Since the primary goal of the problem is to predict buggy files with high accuracy, this was the most relevant metric.\n",
    "#Metrics Not Chosen: FPR (False Positive Rate): While FPR is important, it’s less informative in isolation. It’s more meaningful as part of MCC or in conjunction with precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d09fafe-f77e-4611-a609-58e85bf4b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6:\n",
    "#The choice of features directly impacts the models ability to generalize and make accurate predictions:\n",
    "\n",
    "#All Features: Models trained on all features performed well, but they include irrelevant or redundant information. For example, Random Forest with all features had an accuracy of 93.79%, slightly lower than selected features due to noise.\n",
    "\n",
    "#Static Features Only: Models trained only on static features struggled, achieving significantly lower accuracy and MCC scores. For example:\n",
    "Logistic Regression: 79.31% Accuracy, 0.33 MCC\n",
    "Random Forest: 74.48% Accuracy, 0.27 MCC\n",
    "#This highlights that static features alone don’t capture enough information for accurate predictions.\n",
    "\n",
    "#Change Features Only:\n",
    "#Change features significantly improved performance compared to static features. For instance:\n",
    "Random Forest: 90.34% Accuracy, 0.742 MCC\n",
    "SVM: 91.72% Accuracy, 0.798 MCC\n",
    "#Change features like SUM_LOC+ and MAX_CHRN provide dynamic insights about code changes, which are highly predictive of bugs.\n",
    "\n",
    "#Selected Features:\n",
    "#Carefully selected features (e.g., top 10 from SelectKBest) led to the best overall performance. For example:\n",
    "Random Forest: 95.86% Accuracy, 0.894 MCC\n",
    "Removing redundant or irrelevant features reduced noise and improved generalization.\n",
    "#Evidence:The Selected Features consistently outperformed other sets across all algorithms, demonstrating the importance of feature selection in improving model performance.\n",
    "#For example:\n",
    "Random Forest: Selected Features (95.86% Accuracy, 0.894 MCC) vs. All Features (93.79% Accuracy, 0.837 MCC).\n",
    "Logistic Regression: Selected Features (86.21% Accuracy, 0.616 MCC) vs. All Features (89.66% Accuracy, 0.720 MCC)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
